<workflow>
  <critical>The workflow execution engine is governed by: {project-root}/_bmad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and language MUST be tailored to {user_skill_level}</critical>
  <critical>Generate all documents in {document_output_language}</critical>

  <!-- v2: Two-stage subagent review replaces single-agent adversarial self-review -->
  <critical>
    TWO-STAGE CODE REVIEW ‚Äî Per superpowers:requesting-code-review pattern.

    STAGE 1 (Spec Compliance): Does the code match the story exactly?
      - Each AC is actually implemented (not just marked)
      - Each task marked [x] is actually done
      - Nothing extra built (YAGNI) ‚Äî no features beyond what the story requires
      - Nothing missing ‚Äî all story requirements satisfied
      This stage is PASS/FAIL. Loop until PASS.

    STAGE 2 (Code Quality): Is the code well-built?
      - Security: injection risks, missing validation, auth issues
      - Performance: N+1 queries, inefficient loops, missing caching
      - Architecture: split-brain compliance, pattern adherence
      - Test quality: real assertions vs placeholder tests
      - Maintainability: complexity, naming, duplication
      This stage reports issues by severity. Loop until Critical/Important fixed.

    SUBAGENT ISOLATION: Each review stage should run with FRESH context ‚Äî not the same
    context that implemented the code. In Claude Code, dispatch via the Task tool.
    In other environments, use the equivalent isolation mechanism.
    Self-review (same context reviewing its own code) is insufficient and biased.
  </critical>
  <critical>
    PR COMMENT HANDLING: Follow superpowers:receiving-code-review for human feedback.
    Verify before implementing. Push back with technical reasoning if wrong.
    No performative agreement ("Great point!", "You're absolutely right!").
  </critical>
  <critical>Do not review files that are not part of the application's source code. Always exclude
    _bmad/, _bmad-output/, .cursor/, .windsurf/, .claude/ folders from review.</critical>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
       STEP 1: Load story and discover changes
       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="1" goal="Load story and discover changes">
    <action>Use provided {{story_path}} or ask user which story file to review</action>
    <action>Read COMPLETE story file</action>
    <action>Set {{story_key}} = extracted key from filename (e.g., "1-2-user-authentication.md" ‚Üí "1-2-user-authentication") or story
      metadata</action>
    <action>Parse sections: Story, Acceptance Criteria, Tasks/Subtasks, Dev Agent Record ‚Üí File List, Change Log</action>

    <!-- Discover actual changes via git -->
    <action>Check if git repository detected in current directory</action>
    <check if="git repository exists">
      <action>Run `git status --porcelain` to find uncommitted changes</action>
      <action>Run `git diff --name-only` to see modified files</action>
      <action>Run `git diff --cached --name-only` to see staged files</action>
      <action>Run `git diff main..HEAD --name-only` to see all changes on feature branch</action>
      <action>Compile list of actually changed files from git output</action>
      <action>Record BASE_SHA (merge-base with main) and HEAD_SHA for review context</action>
    </check>

    <!-- Cross-reference story File List vs git reality -->
    <action>Compare story's Dev Agent Record ‚Üí File List with actual git changes</action>
    <action>Note discrepancies:
      - Files in git but not in story File List ‚Üí flag for review
      - Files in story File List but no git changes ‚Üí flag as potential false claim
      - Missing documentation of what was actually changed
    </action>

    <invoke-protocol name="discover_inputs" />
    <action>Load {project_context} for coding standards (if exists)</action>

    <action>Prepare review context package (to be provided to review subagents):
      - Story file path and content
      - Acceptance Criteria (full text)
      - Tasks/Subtasks with completion status
      - File List (story-claimed + git-discovered)
      - Git discrepancies found
      - BASE_SHA and HEAD_SHA
      - Project coding standards
    </action>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
       STEP 2: Stage 1 ‚Äî Spec Compliance Review
       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="2" goal="Dispatch spec compliance review (fresh context)">
    <critical>
      This review MUST run in isolated/fresh context ‚Äî not the same context that
      implemented the code. The reviewer should have NO memory of implementation
      decisions, only the story requirements and the actual code.
    </critical>

    <action>Dispatch a fresh review agent with the following context and directive:

      CONTEXT PROVIDED:
      - Story file (full content, especially Acceptance Criteria and Tasks/Subtasks)
      - Implementation plan file (if exists at docs/plans/*-{story-key}-plan.md)
      - File List: all files claimed changed (story + git-discovered)
      - Git diff summary: BASE_SHA..HEAD_SHA
      - Project coding standards

      DIRECTIVE:
      You are a Spec Compliance Reviewer. Your ONLY job is to verify the implementation
      matches the story specification exactly. You are not reviewing code quality.

      For EACH Acceptance Criterion:
        1. Read the AC requirement word by word
        2. Search implementation files for evidence it is satisfied
        3. Rate: IMPLEMENTED, PARTIAL, or MISSING
        4. If PARTIAL or MISSING: cite what is missing and where

      For EACH Task marked [x]:
        1. Read the task description
        2. Find evidence in the code that it was actually done
        3. If marked [x] but NOT done: CRITICAL finding ‚Äî cite file:line

      YAGNI Check:
        1. Identify any code that does NOT map to a story task or AC
        2. Flag as YAGNI violation ‚Äî code should be removed

      Git vs Story Check:
        1. Files in git but not in story File List ‚Üí incomplete documentation
        2. Files in story File List but not in git ‚Üí false claim

      OUTPUT FORMAT:
      - Overall: PASS or FAIL
      - AC Status: table of each AC with IMPLEMENTED/PARTIAL/MISSING
      - Task Audit: table of each [x] task with VERIFIED/NOT_DONE
      - YAGNI Violations: list (if any)
      - Git Discrepancies: list (if any)
      - Issues found: list with severity (CRITICAL/HIGH/MEDIUM)
    </action>
  </step>

  <step n="3" goal="Handle spec compliance results">
    <check if="spec compliance PASS">
      <output>**Stage 1: Spec Compliance ‚Äî PASS**
        All acceptance criteria verified. All tasks confirmed done. No YAGNI violations.
      </output>
      <action>Proceed to Stage 2 (code quality review)</action>
    </check>

    <check if="spec compliance FAIL">
      <output>**Stage 1: Spec Compliance ‚Äî FAIL**
        {{spec_issues_summary}}
      </output>

      <ask>Spec compliance issues found (see above).

        1. **Fix them now** ‚Äî I'll address each gap and re-run spec review
        2. **Create action items** ‚Äî Add to story as review follow-ups
        3. **Show details** ‚Äî Deep dive into specific issues

        Choose [1], [2], or [3]:</ask>

      <check if="user chooses 1">
        <action>For each CRITICAL and HIGH spec issue:
          - Fix the implementation gap
          - Run quality gate: npm run lint &amp;&amp; npm run typecheck &amp;&amp; npm run build &amp;&amp; npm test
          - Update story File List if files changed
          - Commit: fix({{story_key}}): address spec compliance gap ‚Äî {description}
          - Push: git push
        </action>
        <action>Re-dispatch spec compliance review (return to step 2)</action>
      </check>

      <check if="user chooses 2">
        <action>Add "Review Follow-ups (AI)" subsection to Tasks/Subtasks</action>
        <action>For each issue: `- [ ] [AI-Review][Severity] Description [file:line]`</action>
        <action>Proceed to Stage 2 despite spec gaps (user accepted risk)</action>
      </check>
    </check>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
       STEP 4: Stage 2 ‚Äî Code Quality Review
       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="4" goal="Dispatch code quality review (fresh context)">
    <critical>
      This review MUST run in isolated/fresh context ‚Äî separate from both the
      implementer AND the spec reviewer. Fresh perspective catches different issues.
    </critical>

    <action>Dispatch a fresh review agent with the following context and directive:

      CONTEXT PROVIDED:
      - Story file (for understanding intent)
      - Spec compliance results from Stage 1
      - File List: all changed files
      - Git diff: BASE_SHA..HEAD_SHA (full diff content)
      - Project coding standards
      - Architecture docs (relevant sections)

      DIRECTIVE:
      You are a Code Quality Reviewer. Spec compliance has already been verified.
      Your job is to assess whether the code is well-built. Find real problems.

      Review EACH changed file for:
        1. **Security**: Injection risks, missing input validation, auth bypass, OWASP top 10
        2. **Performance**: N+1 queries, O(n^2) where O(n) is possible, missing caching, unnecessary DB calls
        3. **Architecture**: Split-brain rule violations (mercur-db vs sidedecked-db), pattern adherence, coupling
        4. **Test Quality**: Real behavior tests vs mock-heavy placeholders, edge case coverage, assertion quality
        5. **Maintainability**: Complexity, naming, duplication, magic numbers, overly long functions
        6. **Error Handling**: Missing try/catch at boundaries, poor error messages, swallowed errors

      SEVERITY LEVELS:
        - CRITICAL: Security vulnerability, data corruption risk, crash in production
        - IMPORTANT: Performance problem, architecture violation, missing error handling
        - MINOR: Style, naming, small improvements

      OUTPUT FORMAT:
      - Overall: APPROVED, CHANGES_NEEDED, or BLOCKED
      - Strengths: 2-3 things done well (be specific, cite files)
      - Issues: list with severity, file:line, description, suggested fix
      - Issue count: {{critical}} Critical, {{important}} Important, {{minor}} Minor
    </action>
  </step>

  <step n="5" goal="Handle code quality results and present combined report">
    <check if="code quality APPROVED">
      <output>**Stage 2: Code Quality ‚Äî APPROVED**
        {{strengths_summary}}
        {{minor_issues_if_any}}
      </output>
    </check>

    <check if="code quality CHANGES_NEEDED or BLOCKED">
      <output>**Stage 2: Code Quality ‚Äî {{quality_verdict}}**
        {{quality_issues_summary}}
      </output>

      <ask>Code quality issues found (see above).

        1. **Fix Critical + Important now** ‚Äî I'll fix and re-run quality review
        2. **Create action items** ‚Äî Add to story as review follow-ups
        3. **Show details** ‚Äî Deep dive into specific issues

        Choose [1], [2], or [3]:</ask>

      <check if="user chooses 1">
        <action>Fix all CRITICAL issues immediately</action>
        <action>Fix all IMPORTANT issues</action>
        <action>Note MINOR issues (fix if quick, skip if not)</action>
        <action>Run quality gate: npm run lint &amp;&amp; npm run typecheck &amp;&amp; npm run build &amp;&amp; npm test</action>
        <action>Commit: fix({{story_key}}): address code quality findings ‚Äî {description}</action>
        <action>Push: git push</action>
        <action>Re-dispatch code quality review (return to step 4)</action>
      </check>

      <check if="user chooses 2">
        <action>Add issues to "Review Follow-ups (AI)" subsection</action>
        <action>For each issue: `- [ ] [AI-Review][Severity] Description [file:line]`</action>
      </check>
    </check>

    <!-- Combined report -->
    <action>Set {{fixed_count}} = total issues fixed across both stages</action>
    <action>Set {{action_count}} = total action items created</action>

    <output>**Combined Code Review Report**

      **Story:** {{story_file}}
      **Spec Compliance:** {{spec_verdict}} (Stage 1)
      **Code Quality:** {{quality_verdict}} (Stage 2)
      **Issues Found:** {{critical_count}} Critical, {{important_count}} Important, {{minor_count}} Minor
      **Issues Fixed:** {{fixed_count}}
      **Action Items Created:** {{action_count}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
       STEP 6: Update story status and sync sprint tracking
       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="6" goal="Update story status and sync sprint tracking">
    <!-- Determine new status based on review outcome -->
    <check if="spec compliance PASS AND quality APPROVED AND all issues fixed">
      <action>Set {{new_status}} = "done"</action>
      <action>Update story Status field to "done"</action>
    </check>
    <check if="issues remain unfixed (action items created)">
      <action>Set {{new_status}} = "in-progress"</action>
      <action>Update story Status field to "in-progress"</action>
    </check>
    <action>Save story file</action>

    <!-- Determine sprint tracking status -->
    <check if="{sprint_status} file exists">
      <action>Set {{current_sprint_status}} = "enabled"</action>
    </check>
    <check if="{sprint_status} file does NOT exist">
      <action>Set {{current_sprint_status}} = "no-sprint-tracking"</action>
    </check>

    <!-- Sync sprint-status.yaml -->
    <check if="{{current_sprint_status}} != 'no-sprint-tracking'">
      <action>Load the FULL file: {sprint_status}</action>
      <action>Find development_status key matching {{story_key}}</action>

      <check if="{{new_status}} == 'done'">
        <action>Update development_status[{{story_key}}] = "done"</action>
        <action>Save file, preserving ALL comments and structure</action>
        <output>‚úÖ Sprint status synced: {{story_key}} ‚Üí done</output>
      </check>

      <check if="{{new_status}} == 'in-progress'">
        <action>Update development_status[{{story_key}}] = "in-progress"</action>
        <action>Save file, preserving ALL comments and structure</action>
        <output>üîÑ Sprint status synced: {{story_key}} ‚Üí in-progress</output>
      </check>

      <check if="story key not found in sprint status">
        <output>‚ö†Ô∏è Story file updated, but sprint-status sync failed: {{story_key}} not found in sprint-status.yaml</output>
      </check>
    </check>

    <check if="{{current_sprint_status}} == 'no-sprint-tracking'">
      <output>‚ÑπÔ∏è Story status updated (no sprint tracking configured)</output>
    </check>

    <output>**‚úÖ Code Review Complete!**

      **Story Status:** {{new_status}}
      **Spec Compliance:** {{spec_verdict}}
      **Code Quality:** {{quality_verdict}}
      **Issues Fixed:** {{fixed_count}}
      **Action Items Created:** {{action_count}}

      {{#if new_status == "done"}}Both review stages passed. Story is done.{{else}}Address the action items and re-run code review.{{/if}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
       PR COMMENT HANDLING ‚Äî Read, Fix, Respond, Resolve, Merge
       Per superpowers:receiving-code-review
       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="7" goal="Discover and read PR comments across all story repos">
    <action>Derive the feature branch name for this story: "feature/{{story_key}}"</action>
    <action>Identify all repos that may have PRs for this branch (root repo + child repos: backend/, customer-backend/, storefront/, vendorpanel/)</action>
    <action>For EACH repo, check if a PR exists for the feature branch:
      - cd into the repo directory
      - Run: gh pr list --head feature/{{story_key}} --json number,title,url,state
      - Record: repo path, PR number, PR URL, PR state
      - cd back to root
    </action>
    <check if="no PRs found in any repo">
      <output>No open PRs found for feature/{{story_key}} in any repo ‚Äî skipping PR comment handling.</output>
      <action>Exit this step and proceed to final summary</action>
    </check>
    <action>For EACH open PR found, read all comments:
      - Run: gh pr view {pr_number} --comments --json comments,reviewComments,reviews
      - Collect all review comments (inline code comments) and general PR comments
      - For each comment record: comment_id, file, line (if inline), author, body, resolved status
    </action>
    <action>Categorize each unresolved comment:
      - CHANGE_REQUEST: requires code or test modification
      - QUESTION: requires a written response only
      - SUGGESTION: optional improvement (accept or decline)
      - Already resolved: skip entirely
    </action>
    <action>Set {{total_pr_comments}} = total unresolved comments across all PRs</action>
    <output>**PR Comment Triage**

      | Repo | PR | URL | CHANGE_REQUEST | QUESTION | SUGGESTION |
      |---|---|---|---|---|---|
      (one row per repo with an open PR)

      Total unresolved comments: {{total_pr_comments}}
    </output>
  </step>

  <step n="8" goal="Address PR comments per superpowers:receiving-code-review">
    <critical>
      Follow superpowers:receiving-code-review for ALL human feedback:
      1. READ complete feedback without reacting
      2. UNDERSTAND: Restate the requirement in own words (or ask for clarification)
      3. VERIFY: Check against codebase reality ‚Äî is the suggestion technically correct?
      4. EVALUATE: Technically sound for THIS codebase? Breaks existing functionality?
      5. RESPOND: Technical acknowledgment or reasoned pushback
      6. IMPLEMENT: One item at a time, test each

      FORBIDDEN responses: "You're absolutely right!", "Great point!", "Thanks for catching that!"
      Instead: state the fix, or push back with technical reasoning.

      If suggestion seems wrong: push back. Reference working tests/code. Involve user if architectural.
      If can't verify: say so ‚Äî "I can't verify this without [X]. Should I investigate?"
      If conflicts with prior architectural decisions: STOP and discuss with {user_name}.
    </critical>

    <action>Address comments IN ORDER per PR: CHANGE_REQUEST first, then QUESTION, then SUGGESTION</action>

    <action>For EACH CHANGE_REQUEST comment:
      1. Read the full comment ‚Äî understand exactly what is requested
      2. VERIFY: Is this technically correct for this codebase? Check against actual code.
      3. If CORRECT: make the change, run quality gate, commit, push, respond with what changed, resolve
      4. If INCORRECT: push back with technical reasoning citing specific code/tests, resolve with explanation
      5. If UNCLEAR: ask for clarification before implementing anything
      6. Quality gate after each fix: npm run lint &amp;&amp; npm run typecheck &amp;&amp; npm run build &amp;&amp; npm test
      7. Commit: fix({{story_key}}): address review comment ‚Äî {brief description}
      8. Push: git push
      9. Reply in thread: gh api -X POST repos/{owner}/{repo}/pulls/comments/{comment_id}/replies -f body="{response}"
    </action>

    <action>For EACH QUESTION comment:
      1. Read the question carefully
      2. Formulate a clear, factual answer based on actual implementation
      3. Reply in thread
      4. Resolve
    </action>

    <action>For EACH SUGGESTION comment:
      1. YAGNI check: grep codebase for actual usage ‚Äî is this feature needed?
      2. If ACCEPTING: implement, commit, push, reply stating what changed, resolve
      3. If DECLINING: reply with specific technical reason (out of scope, YAGNI, conflicts with X), resolve
    </action>

    <action>After all comments for a given PR are addressed:
      - Run: gh pr view {pr_number} --json reviewDecision,reviewRequests
      - Note if re-review was requested
    </action>

    <output>**PR Comment Resolution Summary**

      | Repo | PR | Resolved | Commits Made | Pushbacks | Re-review Requested? |
      |---|---|---|---|---|---|
      (one row per PR)
    </output>
  </step>

  <step n="9" goal="Merge PRs once all comments are resolved">
    <critical>Only merge a PR when ALL comment threads are resolved and no CHANGES_REQUESTED review blocks it</critical>

    <action>For EACH PR in order:
      1. Verify no remaining unresolved threads:
         gh pr view {pr_number} --json reviewThreads
      2. Verify no blocking CHANGES_REQUESTED reviews:
         gh pr view {pr_number} --json reviews
      3. If all clear:
         a. Post a merge summary comment:
            gh pr comment {pr_number} -b "All review comments addressed. Merging."
         b. Merge the PR with squash:
            gh pr merge {pr_number} --squash --delete-branch
         c. Confirm merge success and record the merge commit SHA
      4. If unresolved threads or blocking reviews remain:
         a. List the outstanding threads
         b. Return to step 8 to address the new or remaining comments before retrying merge
    </action>

    <check if="any PR still has unresolved threads after retry">
      <action>Report the specific unresolved threads and which reviewer must take action</action>
      <action>Do NOT force-merge ‚Äî stop and surface the blocker to the user</action>
    </check>

    <output>**Merge Summary**

      | Repo | PR | Merged? | Merge Commit | Notes |
      |---|---|---|---|---|
      (one row per PR)
    </output>
  </step>

</workflow>
